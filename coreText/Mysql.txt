Mysql学习
系统表空间就是用来放系统信息的，比如数据字典什么的，对应的磁盘文件是ibdata1,
数据表空间就是一个个的表数据文件，对应的磁盘文件就是 表名.ibd

1、更新频繁的表不适合使用查询缓存(key为查询语句 value为查询结果)

2、redo log(重做日志，InnoDB引擎特有) WAL(Write-Ahead Logging)先写日志再写磁盘，在更新操作时
但redo log也是有固定大小的，所以在写满之后，必须先将修改写入磁盘擦除旧日志后才能继续写日志
write-pos(记录写到哪个位置) check-point(当前要擦除的位置)。当wp追上了cp，就得停下来先做擦除
因为有redo log所以当数据库发生异常重启时，也不会丢失之前做的修改操作，这个能力称之为crash-safe

 binlog(归档日志)，两个日志需要用两阶段提交，不然用日志恢复的数据库可能和原库不一致
 Binlog有两种模式，statement 格式的话是记sql语句，row格式会记录行的内容，记两条，更新前和更新后都有。
 
 3、事务隔离级别isolation (initial-param:transaction-isolation)
 读未提交
 读提交 READ-COMMITTED。每个语句执行前都会重新生成一个新的read-view
 可重复读 REPEATABLE-READ(核心一致性读 consistent read)：
 事务开始时会创建一个read-view，在事务执行期间有其他事务修改了数据，此事务看到的还是原来的视图
 串行化
 
 建议少使用长事务。会占用很多空间存储回滚段，还会占用锁资源
 所以建议使用set autocommit=1，需要事务时显示开启事务begin transaction
 
 4、索引常见数据模型
 哈希表  只适用于等值查询，范围查询效率会很慢，因为他不是有序的
 有序数组 只适用于静态存储引擎(如2021年某个城市所有人口信息)，因为更新数据成本太高
 搜索树 二叉树：左节点小于父节点，父节点小于右节点。当为平衡二叉树时查询时间复杂度O(logN)
 但当数据量大的时候，二叉树的树高会很大，查询效率会因读取过多数据块而变低
 所以推荐使用N叉数
 
 5、InnoDB的索引模型 B+Tree 表都是根据主键顺序以索引形式存放的(索引组织表)。
 根据叶子节点的内容可以分为主键索引和非主键索引
 主键索引(聚簇索引)的叶子节点存的是整行数据，而非主键索引(二级索引)的叶子节点存放的是主键的值
 基于主键索引查询和普通索引查询有什么取别呢？
 主键查询只需要搜索主键索引这颗B+树，而普通索引查询则需要搜索普通索引B+树得到主键的值，然后再到主键索引B+树搜索一次，这个过程称为回表
 因此我们在应用中尽量多使用主键查询。
 
 6、B+树会自己维护索引的有序性，插入新值时会做必要的维护
 自增主键是指自增列上定义的主键，NOT NULL PRIMARY KEY AUTO_INCREMENT。
 建议使用自增主键，一是性能好，插入新数据不涉及挪动其他数据也不会有分裂，删除也不会出现合并现象。
 二存储空间，普通索引的叶子节点大小会相对业务字段做主键占用空间小，整形只需要4个字节，长整形(bigint)则为8
 也可使用业务逻辑字段做主键的场景，有且只有一个唯一索引
 
 7、覆盖索引，减少树的搜索次数，显著提升查询效率。
 有个人口信息表，有id、id_card、name、age、isMale字段，主键为id。
 目前有个根据id_card查找姓名的高频请求，建立覆盖索引就很有必要了，可以去掉回表查找整行数据的动作。
 只需要建立(id_card,name)的联合索引，此索引已经覆盖了我们的查询需求，只需搜索这个索引树即可完成查询动作
 
 8、最左前缀原则，B+Tree这种索引结构，可以利用索引的最左前缀来定位记录。
 例子，我们建立联合索引(name,age) 当查询语句为name='张三'时，我们知道可以直接使用这个联合索引快速定位
 因为这个最左前缀原则，我们的查询条件为name like '张%'时，也能够用上这个索引，查找到第一个符合这个条件的记录，然后向右遍历，直至不满足条件为止。
 我们在建立联合索引考虑索引内字段顺序时，首先需要考虑的是索引的复用能力。当我们建立了(a,b)联合索引后，一般是不需要再单独建立a的索引了。
 第二，我们在当既有联合查询又有基于a,b各自的单独查询时，此时就要考虑a和b字段哪个字段空间占用小，这个字段就适合放在后面，再建立b的单独索引，可以减小空间占用
 
 9、索引下推，在Mysql5.6及以上版本引入了这个原则。在索引遍历的过程中，对查询语句中有包含的索引字段先做判断，直接过滤掉不满足的记录，减少回表次数
 例如，有(name,age)的联合索引，现在查询条件为name like '张%' and age = 10，在5.6之前搜索索引树会把所有张开头的记录都进行回表再判断age条件
 但5.6引用了索引下推之后，搜索这个索引树直接会把age不等于10的记录过滤掉，大大减少回表次数
 
 10、全局锁、表级锁
 全局锁 flush table with write lock,一般用于数据备份时使用。如果是InnoDB引擎，则推荐使用single-transaction参数，开启一个事务建立一致性试图
 表级锁 显示加锁lock tables xxx read/write
 MDL(metadata lock元数据锁，不需要显示使用，在访问一张表的时候会自动加上)
 读锁之间不互斥，可以多个线程同时增删改查。读写锁、写锁之间互斥，所以需要对一张表进行表结构操作，则需要等之前的操作执行完才能执行
 操作不当时对一张小表进行表结构操作也可能会出现问题，在查询频繁的表中且客户端有重试机制的情况下，对此表进行表结构操作很可能导致库线程爆满
 查询操作需要MDL读锁，表结构操作需要MDL写锁，读写锁互斥，当有MDL读锁占用时，表结构操作就会被阻塞，且之后需要申请MDL读锁的操作也会被阻塞，即这张表所有操作都被锁住了
 事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放
 所以如何操作小表的表结构变化呢，方法一可以kill掉此表的长事务，即释放MDL读锁。方法二给alter table加上等待时间(wait n)，等待时间过完还没拿到MDL写锁就先放弃，不阻塞后来操作
 
 11、行级锁，MyISAM引擎不支持行锁
 InnoDB引擎的行锁(通过锁索引记录实现的)，需要时就会加上，但不需要后不会立即释放，而是要等事务结束才释放，这就是两阶段锁协议
 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放，减少占用热点锁的时间
 当两个事务竞争对方都持有的锁时，就会发生死锁。死锁解决方式有两种，一直接进入等待直到超时，通过设置innodb_lock_wait_timeout参数。
 另一种策略就是开启死锁检测，发现死锁后，主动回滚死锁链中的某个事务，让其他事务得以进行。设置innodb_deadlock_detect参数为on，表示开启策略
 
 热点行开始死锁检测时，当有1000个线程同时对一行数据进行修改时，死锁检测就会达到100万量级，导致cpu利用率过高每秒执行的事务却很少。
 解决方法，就是控制访问相同资源的并发事务量，或者当你确定不会发生死锁时，关闭死锁检测(不推荐)
 
 12、InnoDB 利用了“所有数据都有多个版本”的这个特性(row trx_id)，实现了“秒级创建快照”的能力(快照可以理解为一致性视图)
 快照会把当前活跃的事务都记录到数组里(视图数组)，最小的row trx_id放在低水位，最大的row trx_id+1为高水位。在此之前的为绿色区域可见，高水位后的为红色区域不可见
 在中间，若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。
 总结，一个数据版本，对于一个事务视图来说除了他自己的更新总是可见的外
 一版本未提交，不可见；二版本已提交，但是在视图创建之后的，不可见;三版本已提交，在视图创建前提交，可见
 
 更新数据都是先读后写的，而这个读只能读当前的值，称为current read。但如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待
 select也有当前读，加上lock in share mode(加了读锁)或者for update(加了写锁)
 所以RR模式下，很容易产生乐观锁。即现在开启一个事务更新数据where条件后有column=xx，执行完却发现更新失败。这是什么情况呢，
 在update语句之前有其他事务更新并提交了column字段，此时我们事务执行update时看到的是当前值，所以我们的条件语句不再正确。但在此事务中我们正常select看到的是有这条数据的
 
 13、change buffer，只有普通索引可以使用不适用唯一索引。因为唯一索引表更新操作的时候需要去读数据页到内存判断是否满足唯一性，破坏了change buffer原理
 change buffer即当数据页没在内存中时，将更新数据先写入change buffer中，当下次使用到这个数据页时再merge更新内容。change buffer 记录的变更越多，收益越大
 change buffer用的是buffer pool里的内存，可以通过innodb_change_buffer_max_size来动态设置
 change buffer 和redo log，一个是节省随机读磁盘的IO消耗(只有当将此数据页读到内存中，才会触发change buffer的merge操作)，另一个主要是节省随机写磁盘的IO消耗
 
 普通索引和唯一索引，在更新频繁的表中尽量使用普通索引并把change buffer开大，以提高表数据的写入速度
 
 14、如果索引统计不准确(show index from t)可以使用analyze table t来解决问题，但也不是能解决所有问题
 可以用explain 语句来查看使用的索引以及扫描的行数
 当有a b两个普通索引时，查询条件where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1;
 明显使用a作为索引只会扫描1000行，而b会扫描50000行，此时优化器还是会选择b作为查询索引。
 可以使用force index(a)来解决，但这么解决当索引名称改变时又需要重新修改不够优雅，我们就来分析为什么优化器会选择索引b
 因为order by b，优化器认为直接使用索引b可以省掉排序动作(索引本身就是有序的)，所以即使扫描行数更多也判定为代价更小
 但因为有limit 1所以 order by b limit 1 和 order by b,a limit 1逻辑是一致的，这样改之后优化器就会选择扫描行数少的a
 
 15、merge 的执行流程是这样的：
 从磁盘读入数据页到内存（老版本的数据页）；从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；
 写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。到这里 merge 过程就结束了。这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了
 
 16、(字符串字段加索引)前缀索引，节省索引占用空间。add index(column_name(num))
 使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本
 定义长度的策略，定义最多损耗区分度百分比，用distinct_left(xx,num)的值/count(distinct xx)，来判断是否满足损耗区分度，若满足则可选用这个长度值
 前缀索引用不上覆盖索引对查询的性能优化。覆盖索引不需要回表，查询结果可直接返回，但用了前缀索引不管是否包含所有信息都会回表再查一遍。
 
 当使用前缀索引区分度很低的时候，如身份证号的前六位同一个地区的人一般都是相同的，这时怎么办呢
 第一种方法倒序存储，查询的时候id_card=reverse('input')
 第二种方法hash字段，新增一个整数字段来存储身份证的校验码，同时在这个字段上创建索引，
 但由于不同身份证号的校验码可能存在相同，所以查询条件就变成了id_card_crc=crc32('input') and id_card = 'input'才能保证查询结果精准无误
 这样索引长度就变成了4个字节的整型。
 这两种方法都不支持范围查询，hash字段只支持等值查询。
 
 17、内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”
 之所以相同的语句有时候执行很快有时候却很慢呢。快的时候可能只写了内存和日志，而Mysql偶尔“抖”的那下可能就是在刷脏页(flush)
 什么情况下会刷脏页？
 第一redo log记满了，需要把check point 往前移，此时就需要将内存里的脏页flush到磁盘里；
 第二内存满了，需要清理内存，也会flush到磁盘。有人会说了直接把内存清理，之后再根据redo log应用不就行了？要保证数据页只有两种状态：
 一在内存当中，一定是最新数据可以直接拿。二不在内存中，那么数据文件中一定是正确数据，读入内存后返回。
 第三Mysql空闲时，flush脏页
 第四Mysql正常关闭时，会把内存中所有的脏页flush进磁盘
 
 18、InnoDB刷脏页的控制策略，innodb_io_capacity这个参数会告诉InnoDB你的磁盘能力，建议设置成IOPS
 innodb_max_dirty_pages_pct参数，脏页比例上限，默认值是 75%，脏页比例经过计算得到M
 check point 和 write position的差值经过计算得到N，max(M,N)%*innodb_io_capacity就是你处理脏页的速度
 
 InnoDB一个有趣刷脏页的机制，innodb_flush_neighbors参数用来控制是否刷相邻脏页且可以蔓延。1刷0不刷
 
 19、数据库表空间的回收。
 innodb_file_per_table参数，设置为off表示表的数据放在系统共享表空间里，也就是跟数据字典放在一起。为on，则每张innodb的表数据存储一个t.ibd的文件。
 
 InnoDB引擎的删除是标记删除，即引擎只会把这条数据标记为删除。后续如果有在此记录前后索引范围内的值需要插入，可能会复用这个位置。
 同样的我们删除整个数据页的数据，整个数据页就可以被复用了。但数据页的复用和记录的复用是不同的，数据页的复用不一定需要主键索引在某个范围内才能复用。
 数据页的合并，会将另一个数据页标记为可复用。delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。这就是“空洞”
 同样，插入更新也可能造成数据空洞，插入可能会造成数据页分裂，此时就会产生空洞。更新可以理解为删除旧值插入新值，也会造成空洞。
 也就是说，经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。而重建表，就可以达到这样的目的
 
 20、重建表：alter table t1 engine=InnoDB,ALGORITHM=copy/inplace,这是个DDL语句，所以会获取MDL写锁，但在真正拷贝数据之前就退化成读锁了，所以在5.6版本之前这个操作是不允许
 有对这个表的增删改查动作的，但在5.6版本之后引入了Online DDL，可以支持拷贝的时候记录表的增删改查操作于row log中，临时文件生成后会应用row log中的操作。
 
 21、optimize table t 等于 recreate+analyze
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 