Redis知识
redis持久化的两种方式
RDB持久化，原理是将Reids在内存中的数据库记录定时dump到磁盘上的RDB持久化

AOF（append only file）持久化，原理是将Reids的操作日志以追加的方式写入文件
AOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录

缓存穿透

缓存雪崩

缓存击穿

基础篇:
1、一个键值数据库包含什么？一个键值数据库包括了访问框架、索引模块、操作模块和存储模块四部分
Key<String>-Value的数据结构<memocached只能存String而Redis很丰富>
可以对数据最基本的操作，PUT、GET、DELETE和SCAN。有些键值数据库的新写/更新操作叫SET
键值对保存在内存还是外存？内存好处读写快(百ns级)，但存在潜在风险丢数据，外存可以避免丢失但读写慢(几ms级)。Memcached 和 Redis 都是属于内存键值数据库

访问框架，网络框架访问(通过网络框架以 Socket 通信的形式对外提供键值对操作)或者动态库访问(通过函数库调用的方式供外部应用使用)。
Memcached和Redis使用的是网络框架(Socket Server 请求解析)

索引模块，索引的作用是让键值数据库根据 key 找到相应 value 的存储位置，进而执行操作
Memcached和Redis 采用哈希表作为 key-value 索引
使用哈希表索引很大一部分原因在于，其键值数据基本都是保存在内存中的，而内存的高性能随机访问特性可以很好地与哈希表时间复杂度(O(1))所匹配

存储模块，内存分配器是键值数据库中的一个关键因素。以内存存储为主的Redis对此提供了多种选择
持久化的两种方案
对于每一个键值对，SimpleKV 都对其进行落盘保存，保证了数据可靠性但性能会受很大影响
SimpleKV 只是周期性地把内存中的键值数据保存到文件中，这样可以避免频繁写盘操作的性能影响，但会有丢数据的风险

2、Redis“快的原因”，在内存中进行操作，高效的数据结构
Redis 使用了一个全局哈希表来保存所有键值对，一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶
因为这个哈希表保存了所有的键值对，所以，我也把它称为全局哈希表。我们只需要计算键的哈希值，就可以找到对应哈希桶的位置，使用桶里的entry<K,V>
当往哈希表写入大量数据时，哈希表的冲突问题和 rehash 可能带来的操作阻塞

Redis哈希冲突会使用链表和rehash方法来解决，当链表过长影响性能时，会触发rehash操作。Redis默认两个哈希表(哈希表1和哈希表2)，哈希表2默认不分配空间
rehash过程：
给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；
把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；
释放哈希表 1 的空间
但是第二步涉及大量的数据拷贝，如果一次性把哈希表 1 中的数据都迁移完，会造成 Redis 线程阻塞，无法服务其他请求。
为了避免这个问题，Redis 采用了渐进式 rehash：(当没有键值对操作时，会有定时任务定时rehash;查找会先从ht[0]查找，没有再查找ht[1];新增只会在ht[1]操作)
Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；
等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries

对于String类型来说，通过找到哈希桶就能直接进行增删改查了，所以O(1)就是String类型操作时间复杂度
对于集合来说，他即使找到哈希桶还需要在集合中进一步操作，所以他的效率取决于集合本身底层数据结构的操作复杂度

集合类型的底层数据结构主要有 5 种：整数数组O(N)、双向链表O(N)、哈希表O(1)、压缩列表和跳表
哈希表，set zset hash
压缩列表类似数组，不同的是在压缩列表的表头有三个字段，zlbytes、zltail、zllen。分别表示列表长度、列表尾的偏移量和列表中的 entry 个数，
压缩列表在表尾还有一个 zlend，表示列表结束。如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)，其他元素则是O(N)
跳表，在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。当数据量很大时，跳表的查找复杂度就是 O(logN)

Redis 之所以能快速操作键值对，一方面是因为 O(1) 复杂度的哈希表被广泛使用，包括 String、Hash 和 Set，它们的操作复杂度基本由哈希表决定
另一方面，Sorted Set 也采用了 O(logN) 复杂度的跳表。不过，范围类的操作，因为要遍历底层数据结构，复杂度通常是 O(N)。可以用SCAN来替代，渐进遍历。
复杂度较高的List。例如，既然它的 POP/PUSH 效率很高，那么就将它主要用于 FIFO 队列场景，而不是作为一个可以随机读写的集合

小思考，既然整数数组和压缩列表在查询时间复杂度上没有优势，Redis还把他作为底层数据结构呢？
首先，内存利用率，数据和压缩列表都是非常紧凑的数据结构，它比链表占用的内存更少，Redis是内存型数据库，所以要对内存尽可能优化提高利用率
其次，数组对CPU高速缓存支持更友好，所以Redis在设计的时候，当集合数据量少的时候，默认采用内存紧凑的排列方式存储，同时利用CPU高速缓存不会降低访问速度。
当超过阈值，为避免查询缓慢，再转为哈希表或者跳表数据结构存储

3、我们通常说，Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。
但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的
那为什么单线程的Redis能这么快呢？除了他使用内存和对于底层数据结构的良好选择，
另一方面Redis采用了多路复用机制。使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率

Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字(实现对accept非阻塞)和已连接套接字(实现send、recv非阻塞)。内核会一直监听这些套接字上的连接请求或数据请求。
一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。
select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。select/epoll 一旦监测到FD(套接字)上有请求到达时，就会触发相应的事件
这些事件会被放入事件队列里，Redis单线程对该事件队列不断进行处理。这样一来，Redis无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。
同时，Redis 在对事件队列中的事件(Accept、Read、Write等)进行处理时，会调用相应的处理函数(accept、get等)，这就实现了基于事件的回调

4、AOF日志，不同于WAL(Write-Ahead Log)写前日志，AOF是写后日志，Redis先执行命令把数据写入内存，然后才记录日志
这些命令是以文本形式保存的，Sample "set testKey testValue"，AOF里面存入的是:$3 set $7 testKey $9 testValue 其中数字代表命令、键或值一共有多少字节
写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中。可以避免出现记录错误命令
除此之外，AOF还有一个好处，写后记录不会阻塞当前写操作。但这也带来了潜在风险
可能会丢数据，磁盘写压过大可能会阻塞主线程(AOF日志也是在主线程中执行)。所以写磁盘时机变得尤为重要

三种写回策略，AOF 配置项 appendfsync 的三个可选值
Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘(性能低，数据可靠性高)
Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘(允许丢失一小部分数据，性能也ok)
No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘(高性能，数据可靠性低)

AOF日志文件大小过大怎么办？
AOF重写机制，重写时会根据数据库现状创建一个新的AOF文件，换句话说就是会读取数据库中所有的键值对，并且对每一个键值对用一条命令记录他,例如set testKey testValue
重写机制具有"多条变一条"功能。我们知道AOF是追加形式写入的，所以AOF文件中可能有多条对同一键值对的操作，重写可以将多条操作变一条set、lpush等命令
有了重写机制，问题又来了，重写这么耗时会不会阻塞主线程？
不会，和AOF主线程写回不同，重写是由后台子进程bgrewriteaof来完成的。
简单来说重写就是“一个拷贝，两处日志”，重写会先拷贝一份主线程的内存数据给grewriteaof子进程(fork子进程)，两处日志指的是，因为主线成为阻塞可以继续处理新来的操作，
如果有写操作，第一处日志就是AOF日志的缓冲区，第二处日志是重写日志的缓冲区，这样既保证了宕机AOF日志的齐全性，也保证了重写完成后也会记录这些新操作到新的AOF日志中，
以保证数据最新状况的记录，此时就可以用新AOF替代旧AOF文件了。

5、RDB(Redis database)快照，它实现类似照片记录效果的方式，就是把某一时刻的状态以文件的形式写到磁盘上
RDB需要考虑下面两个问题
对哪些内存数据做快照？
Redis 的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是全量快照，也就是说，把内存中的所有数据都记录到磁盘中。
但全部写入磁盘，会花费很多时间，数据越多RDB文件越大，写数据的时间开销也就越大。针对Redis的任何操作，我们都会发出灵魂拷问"它会阻塞主线程吗？"
Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，save由主线程执行，会阻塞;bgsave创建一个子进程，专门用于写入RDB，不会阻塞主线程，这也是默认配置

快照时数据能修改吗？
我们拍照的时候当然不希望人动，这样就会拍糊需要重新拍摄。但是，执行快照期间如果不允许对快照数据进行写操作，将会对业务造成巨大影响，显然是不能接受的。
所以这个时候，Redis 就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。
bgsave进程是主线程fork生成的，可以共享主线程所有内存数据，bgsave就是读取的内存数据写入RDB文件的。如果此时主线程对快照数据都是读操作，那么主线程和bgsave互不影响，
但是主线程要修改数据时，那么这块数据就会被复制一份，生成该数据的副本，然后主线程是对副本上的数据进行修改。同时,bgsave继续把原来的数据进行写入RDB文件

那么RDB快照可以每秒拍一次的连拍吗？
虽然bgsave不会阻塞主线程，但是fork子进程会阻塞主线程。内存越大，阻塞的时间越长。所以，在Redis中只允许存在一个bgsave子进程
而且大量bgsave会给磁盘带来很大压力，相互之间竞争磁盘带宽
那能不能用增量快照呢，在做完全量快照后，再做快照只需要对被修改过的数据写入快照文件就行了。
但是，这么做的前提是，我们需要记住哪些数据被修改了。我们需要使用额外的元数据信息去记录，会带来额外空间的开销

有没有既可以享受RDB带来的快速恢复，又能以较小的开销做到尽量少丢失数据呢？
Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。
内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作
T1和T2快照之间时刻的修改，用AOF日志记录，等到第二次做全量快照时，就可以清空AOF日志了。
我们在某一时刻宕机了，做数据恢复时，只需要拿上一时刻的RDB文件(二进制数据流)，再加上AOF日志文件就可以快速进行全量恢复了。

6、Redis的高可靠性，一是数据尽量少丢失，二是服务尽量少中断
AOF 和 RDB 保证了前者，而对于后者，Redis 的做法就是增加副本冗余量

多实例保存同一份数据，我们必须要考虑一个问题：这么多副本，它们之间的数据如何保持一致呢？数据读写操作可以发给所有的实例吗？
实际上,Redis提供了主从库模式，以保证数据副本的一致，主从库之间采用的是"读写分离"的方式。
读操作：主库、从库都可以接收；写操作：首先到主库执行，然后，主库将写操作同步给从库

主从库之间如何进行第一次同步？
replicaof命令 replicaof ip port 就可以将次ip实例设置为命令中ip实例的从库(5.0版本之前是 slaveof)。之后会按照三个阶段完成数据的第一次同步。
第一阶段，主从库建立连接、协商同步事宜，主要是为全量复制做准备。具体来说,从库给主库发送psync命令，表示要进行数据同步，主库根据这个命令来启动复制。
命令包含两个参数，主库的runId和复制进度offset，由于是第一次同步不知道主库runId，会用?代替， offset为-1。
主库收到命令后，会用FULLRESYNC响应，并带上两个参数，主库的runId和主库目前的复制进度offset返回给从库。从库收到响应后会记录这两个参数。
FULLRESYNC 响应表示第一次复制采用的全量复制，将所有数据都同步给从库
第二阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件。
具体来说，主库执行bgsave命令，生成RDB文件，接着将文件发送给从库。从库接收到了RDB后会先清空自身内存，然后加载RDB文件。
主库同步数据时，主线程不会阻塞可以正常接受请求。新修改的数据不会记录到RDB文件中，为了保证主从库数据一致性，
主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作
第三阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体是，会将replication buffer中的修改操作发送给从库，从库再执行这些操作，主从同步就实现了。

我们可以设想一下，当从库数量很大时，此时都连接主库进行同步会导致主库忙于fork bgsave子进程生成RDB文件。fork操作会阻塞主线程，导致服务响应变慢
传输RDB文件会占用网络带宽，频繁传输会给主库资源带来压力，有什么办法解决吗？是有的，“主 - 从 - 从”模式
主从模式是所有从库都和主库连接，主库压力山大。我们可以通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上
简单来说可以手动选择一个内存配置资源较好的从库，来用于级联其他从库。可以选择一部分从库让它们和这个从库建立主从关系。

一旦主从完成全量复制，它们之间就会一直维护一个网络连接。后续主库的写操作再同步给从库，这个过程也称为基于长连接的命令传播。
但也存在着风险，最常见的就是网络断连或阻塞。网络断连了怎么办？
当主从断连后，主库会把期间的写操作写入replication buffer(其他未断开从库连接的buffer)中，同时也会把这些操作命令写入repl_backlog_buffer这个缓冲区
repl_backlog_buffer是一个环形缓冲区，主库会记录自己写到的位置(master_repl_offset)，从库则会记录自己已经读到的位置(slave_repl_offset)
在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset 会大于 slave_repl_offset。
此时，主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。
不过，有个地方需要注意，这个缓冲区是环形缓冲区，这意味着当缓冲区写满后，主库还会继续写入，这时就会覆盖掉之前的写入操作。
如果从库读取速度比较慢，就有可能还没有读取就被新的写操作覆盖了，导致主从数据不一致。
此时就需要关注repl_backlog_size这个配置参数了，它设定了repl_backlog_buffer缓冲区的大小。一般来说是主库每秒写操作减去网络每秒传输操作数*操作的大小*2
当slave_repl_offset被覆盖后，主从库重连就会进行全量复制而不是增量复制了。

Redis和客户端通信也好，和从库通信也好都会分配一个内存buffer
replication buffer,用于主节点与各个从节点间数据的批量交互。主库给各个从库都会分配的缓冲区，根据从库处理性能差异，这个缓冲区数据可能各不相同
repl_backlog_buffer,用于主从间的增量同步，主节点只有一个repl_backlog_buffer缓冲区，各个从节点的offset偏移量都是相对该缓冲区而言的。

7、主库挂了，如何不中断服务？
无论是写服务中断还是从库无法进行数据同步，都是无法接受的。所以如果主库挂了，我们就需要运行一个新的主库。比如可以把一个从库切换为主库
这里就面临三个问题：
主库真的挂了吗？该选择哪个从库作为主库？怎么把新主库的相关信息通知给从库和客户端？

这里我们就要提到哨兵机制了。什么是哨兵机制，他的基本流程是什么？
所谓哨兵，其实就是运行在特殊模式下的Redis进程，它主要负责三个任务，监控、选主和通知
监控：通过定时PING来监控主从库
选主：按照一定规则选择一个从库实例把它切换为主库
通知：哨兵会把新主库的信息发送给其他从库，从库执行replicaof 命令，和新主库建立连接，并进行数据复制。同时哨兵也会把新主库的连接信息发送给客户端

哨兵是否会存在误判的情况呢？误判主库下线会带来很大的开销，所以哨兵对下线的判断有"主观下线"和"客观下线"。对主库下线的判断，不会简单把主库标记为"主观下线"
误判一般会发生在集群网络压力较大、网络拥塞，或者是主库本身压力较大的情况下。
它通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。引入多个哨兵实例来一起进行判断，降低误判率。
只有大多数的哨兵实例，都判断主库已经“主观下线”了，主库才会被标记为“客观下线”，判断原则就是少数服从多数(也可以由Redis管理员设置多少哨兵实例判断下线才是客观下线)。

如何选择新主库？
我把哨兵选择新主库的过程称为“筛选 + 打分”。简单来说就是按照一定筛选条件，筛选出来的从库再按照一定打分规则。得分最高的从库选定为新主库
筛选：除了要检查从库的当前在线状态，还要判断它之前的网络连接状态。检查之前主从连接状况(down-after-milliseconds配置项设置连接超时时间)，如果断连超过10次，则判定为网络状态不好
打分：按照三个规则依次进行三轮打分，这三个规则分别是从库优先级、从库复制进度以及从库 ID 号。只要当在某一轮中，有从库得分最高，就选择这个从库作为主库
从库优先级，slave_priority配置参数，当服务器内存不一样时可以自己手动设置优先级;
从库复制进度，选择和旧主库同步最接近的从库。具体来说就是slave_repl_offset距离master_repl_offset最近;
ID号小的从库得分高,在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。

8、部署哨兵集群面临的问题，如果有哨兵实例在运行时发生故障，主从库切换还能正常完成吗？
配置哨兵：sentinel monitor <master-name> <ip> <redis-port> <quorum>
哨兵在配置时并没有相互之前ip的配置项，只有主库的IP和端口，那么他们是怎么组成集群的呢？

基于Redis的Pub/Sub机制的哨兵集群
哨兵只要在主库上建立了连接，就可以在主库上发布消息，比如它自身的连接信息。同时，它也可以订阅消息，获取其他哨兵实例的连接信息
除了哨兵，我们自己编写的应用程序也可以在Redis上进行消息发布和订阅，不同的消息类别将消息进行分类，只有订阅了同一个频道的应用，才能通过发布进行消息交换
在主从集群中，主库上有个名为"__sentinel__:hello"的频道，不同哨兵就是通过它来互相通信的。
通过 pub/sub 机制，哨兵之间可以组成集群，同时，哨兵又通过 INFO 命令，获得了从库连接信息，也能和从库建立连接，并进行监控了
但是哨兵仅和主从库建立连接并不够，还需要通知给客户端新主库信息

基于pub/sub机制的客户端事件通知
从本质上说，哨兵就是一个运行在特定模式下的Redis实例，只不过它并不服务请求操作，只是完成监控、选主、通知三个任务
所以每个哨兵实例也提供pub/sub机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件
具体操作为，客户端读取哨兵连接信息建立连接，在客户端执行订阅命令，来获取不同事件的消息。SUBSCRIBE channel-name / PSUBSCRIBE * 订阅所有频道
当哨兵把新主库选择出来后，客户端就会看到下面的 switch-master 事件。这个事件表示主库已经切换了，新主库ip和端口会显示在消息里
switch-master <master-name> <oldip> <oldport> <newip> <newport>
到这里，通过pub/sub 机制，哨兵和哨兵之间、哨兵和从库之间、哨兵和客户端之间就都能建立起连接了。哨兵集群的监控、选主和通知三个任务就基本可以正常工作了

由哪个哨兵执行主从切换？
判断“客观下线”后的哨兵实例会发起对自己的Leader选举，并给自己投上一票Y。成为leader必须要半数以上的哨兵投票Y，且大于等于quorum(判断客观下线需要的实例数量)值。

配置哨兵集群的经验，要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds。这个值不一致很可能导致主库下线判断无法形成共识

9、切片集群，数据增多了是该加内存还是加实例？加内存简单粗暴
Redis3.0之后提供了Redis Cluster解决方案，将key做CRC16计算然后对哈希槽(Hash slot)总个数取模得到对实例的映射。一个切片集群共有16384个哈希槽
我们在部署Redis Cluster方案时，可以用create cluster命令创建集群，将槽平均分配到集群实例上。也可以用cluster meet命令手动建立实例间的连接，形成集群，
然后再用cluster addslots命令，指定每个实例槽个数。redis-cli -h ip -p port cluster addslots xx
在手动分配哈希槽时，需要把16384个槽都分配完，否则 Redis 集群无法正常工作

客户端如何定位数据？
Redis会将自己的哈希槽信息发给和它相连的其他实例，客户端和集群建立连接后，实例就会把哈希槽的分配信息发送给客户端。
客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了
但在集群中，实例和槽对应关系不是一直不变的，最常见的有两种：
当实例有新增或者删除，Redis需要重新分配哈希槽；
为了负载均衡，Redis需要把哈希槽在实例上重新分配；
Redis Cluster 方案提供了一种重定向机制，即当GET KEY不在请求实例上时，会返回ERROR信息，里面有MOVED slotNum ip:port信息，表示这个槽的数据都移至新的实例上了。
但槽数据的迁移也是需要耗时的，当没有完全迁移完成，此时客户端发送了GET KEY请求旧实例，若没找到，此时则会返回(error) ASK slotNum ip:port，
此时客户端需要先向新实例发送ASKING请求，即让这个实例允许客户端接下来发送命令，然后再向这个实例发送GET命令，以读取数据

MOVED会更新客户端缓存的哈希槽分配信息，ASK不会。

进阶实践篇：
1、String类型，在保存的键值本身占用空间不大时，String类型的元数据开销就占主导了,
这里面包括了 RedisObject 结构、SDS 结构(Simple Dynamic String)、dictEntry 结构的内存开销。
针对这种情况，我们可以使用压缩列表作为底层数据结构来保存数据。Redis 基于压缩列表实现了 List、Hash 和 Sorted Set 这样的集合类型
在想使用设置为压缩列表(ziplist)实现的Hash类型时，要注意两个阈值，一旦超过了阈值，Hash类型就会用哈希表来保存数据了。
hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数
hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度
例如，当某种单值键值对想用压缩列表形式的Hash类型存储时，一定要控制好Hash的key的长度， 
key为三位的数字字符串时表示最多有1000个同种键值对可以保存至Hash集合中，此时我们设置maxEntries为1000就ok了。
sample,我们之前简单String类型键值对的键前7位有很多重复，后3位才对数据有区分度，就可以将前7位设置为Hash类型的键，后3位作为Hash集合中的key

2、使用集合做不同类型的统计，集合的选择问题
聚合统计：适合使用Set类型作为集合类型。统计并集(SUNIONSTORE)、交集(SINTERSTORE)、差集(SDIFFSTORE)
Set的聚合统计的计算复杂度较高，在数据量较大的情况下容易导致Redis实例阻塞。建议选择一个从库专门负责聚合计算，或者把数据读取到客户端，让客户端来完成统计。

排序统计：排序顾名思义就会要求集合类型对元素有序保存。List和Sorted Set就属于有序集合。List是按照元素push List的顺序进行排序，而Sorted Set可以根据元素的权重排序。
List集合，当使用LRANGE key index0 index1命令来实现分页查询的话，假设已经浏览了第一页，此时LPUSH了一个新的元素到List中，翻至第二页就会包含之前第一页的最后一个元素
这是因为，当插入新的元素，所有元素都往后挪了一位，LRANGE实现分页每页的下标并不会变化，所以就可能导致分页数据重复展示
Sorted Set就不会出现这种情况，使用命令ZRANGEBYSCORE Weight0 Weight1进行范围展示，新插入进来的数据权重不会影响到既定权重范围的数据查询。
所以在面对需要展示最新列表、排行榜等情况时，如果数据更新频繁或者需要分页展示时，建议优先考虑Sorted Set集合

二值状态统计：例如统计签到or未签到、在线or离线、有or没有等场景，可以使用Bitmap。
这是Redis扩展的数据类型，Bitmap本身是用String类型作为底层数据结构实现的一种二值状态的数据类型。String类型是会保存为二进制的字节数组，
所以Redis就把字节数组的每个bit位利用起来，用于表示一个二值状态。你可以把Bitmap看作是一个bit数组
Bitmap提供了GETBIT/SETBIT/BITCOUNT操作，使用一个offset偏移位来对bit数组的某一个bit位进行读写。offset从0开始计算
Bitmap支持用BITOP命令对多个Bitmap按位做“与”、“或”、“异或”的操作。例如与:BITOP AND KEYNAME BM1 BM2 BM3
例子，如果记录了 1 亿个用户 10 天的签到情况，如何统计出连续签到10天的总人数？
用天作为key，Bitmap存1亿个bit数据表示这1亿用户当天签到情况，再对10个Bitmap按位与操作，得到的结果BITCOUNT就是连续签到10天的总人数
但Bitmap很大时，建议根据业务使用设置过期时间，以节省内存开销

基数统计：统计一个集合中不重复的元素个数。我们首先想到的就是Set集合，Set集合的去重功能，保证了集合中不会出现相同元素。SCARD命令返回元素个数。
Hash同样也可以用于基数统计，因为Hash集合中的key也不能重复。HLEN命令就可以获取集合中所有元素的个数。
但当数据量很大时，且我们只用这个集合来进行基数统计就会消耗大量内存空间，很显然是不能接受的。
这时就要用到Redis提供的HyperLogLog了，HyperLogLog是一种用于统计基数的数据集合类型。
它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。每个HyperLogLog只需要花费12KB内存，就可以计算接近2^64个元素基数
在统计基数时，用PFADD命令向HyperLogLog中添加新的元素，接下来就可以用PFCOUNT命令直接获取统计值了。
不过有一点需要注意的是，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。
所以当需要精准统计还是得用Set或者Hash。

3、GEO，Redis基于Sorted Set实现的特殊集合类型。主要场景为，需要范围查询且数据需要用key/value保存，范围查询所以排除了Hash。
Sorted Set 类型也支持一个key对应一个value的记录模式。key就是Sorted Set中的元素，value作为元素的权重分数
但当我们的场景为LBS(Location-Based Service)基于位置信息的服务，他的key是人或物，value为一组经纬度(116.034579,39.000452),那么问题来了
Sorted Set元素的权重是一个浮点数float，而一组经纬度包含的是两个值，无法直接保存为浮点数，怎么办呢？
这里就要提到GEOHash编码了，这个方法的基本原理就是“二分区间，区间编码”
当我们要对一组经纬度进行 GeoHash 编码时，我们要先对经度和纬度分别编码，然后再把经纬度各自的编码组合成一个最终编码。
二分区间，就是把数据范围一分为二，实际数据在左边编码0，右边编码1。二分次数N可以自己设定，做完后就可以用N个bit来表示我们的经纬度了。
当一组经纬度各自编码完成后，要组合在一起，组合规则就是，偶数位放经度，奇数位放维度。

如何操作GEO类型？
GEOADD 命令：用于把一组经纬度信息和相对应的一个 ID 记录到 GEO 类型集合中；
GEORADIUS 命令：会根据输入的经纬度位置，查找以这个经纬度为中心的一定范围内的其他元素。当然，我们可以自己定义这个范围
GEOADD cars:locations 116.034579 39.030452 33
GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10，ASC表示升序，ASC COUNT 10表示只查找最近10台车

4、Redis如何自定义数据类型？
RedisObject 的内部组成包括了 type、encoding、lru 和 refcount 4 个元数据，以及 1 个*ptr指针
type：表示值的类型，涵盖了我们前面学习的五大基本类型；
encoding：是值的编码方式，用来表示 Redis 中实现各个基本类型的底层数据结构，例如 SDS、压缩列表、哈希表、跳表等；
lru：记录了这个对象最后一次被访问的时间，用于淘汰过期的键值对；
refcount：记录了对象的引用计数；
*ptr：是指向数据的指针

当我们想自定义一个新的数据类型时，只需要定义好type、encoding，再用*ptr指向新类型的实现就好啦。
具体步骤：
第一步：定义新数据类型的底层结构，用newtype.h文件来保存新类型的定义。比如想要查询效率高，可以自定义一个B+tree类型
第二步：在 RedisObject 的 type 属性中，增加这个新类型的定义。server.h文件中，添加#define OBJ_NEWTYPE NUMBER
第三步：开发新类型的创建和释放函数,Redis把数据类型创建和释放的函数都定义在object.c文件中，
所以我们可以在这个文件中增加新类型对象的创建函数createNewTypeObject。createNewTypeObject分别调用了 newtypeNew 和 createObject 两个函数
newtypeNew，它是用来为新数据类型初始化内存结构的，主要用zmalloc分配底层结构空间。新类型的New函数需定义在新文件t_newtype.c
createObject是Redis本身提供的RedisObject创建函数，包含两个参数，一个就是新类型的type值OBJ_NEWTYPE，以及一个初始化过的新类型指针
释放函数，用zfree命令把新结构的内存空间释放掉
第四步：开发新类型的命令操作
在t_newtype.c文件中增加命令操作的实现。例：void ntinsertCommand(client *c) {//基于客户端传递的参数，实现插入}
在server.h文件中，声明我们已经实现的命令，以便在 server.c 文件引用这个命令。例：void ntinsertCommand(client *c)
在server.c文件中的redisCommandTable里，把新增命令和函数关联起来。例：struct redisCommand redisCommandTable[] = {...{"ntinsert",ntinsertCommand,2,"m",...}}
到此我们就可以使用ntinsert命令给新类型对象插入元素了


缓存篇
1、旁路缓存，使用Redis作为缓存时，我们需要在应用程序中增加三方面的代码：
当应用程序需要读取数据时，我们需要在代码中显式调用 Redis 的 GET 操作接口，进行查询；
如果缓存缺失了，应用程序需要再和数据库连接，从数据库中读取数据；
当缓存中的数据需要更新时，我们也需要在应用程序中显式地调用 SET 操作接口，把更新的数据写入缓存。

缓存类型，按照 Redis 缓存是否接受写请求，我们可以把它分成只读缓存和读写缓存
只读缓存，当需要修改数据A且A也在Redis缓存中时，应用会直接先在数据库里修改A，并把Redis中的A删除。
等到下次应用需要读取数据A时，发生缓存缺失，此时应用从数据库中读取A，并把它写入Redis。好处，数据库中永远是最新数据，有高可靠性
读写缓存，同步直写(写缓存也写数据库，全部成功写完才会给客户端返回)、
异步写回(优先考虑响应时延，所有写请求现在缓存中完成，等到这些数据要被淘汰时缓存将他们写回数据库)此方式Redis不支持,多应用于操作系统page cache或大量写操作的数据引擎中

2、Redis缓存数据淘汰策略。设置缓存大小，CONFIG SET maxmemory 4gb
在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis 4.0 后新增）四种
在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）三种

当我们使用了EXPIRE设置数据过期时间时，不论是到达过期时间还是内存使用到达maxmemory阈值，Redis都会进一步按照volatile这四种策略进行淘汰。
volatile-ttl 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除
volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除
volatile-lru 会使用 LRU 算法筛选设置了过期时间的键值对
volatile-lfu 会使用 LFU 算法选择设置了过期时间的键值对
对于所有键值对的淘汰策略，当一个EXPIRE过的键值对被筛选出来，即使它的过期时间还没到也会被删除
allkeys-random 策略，从所有键值对中随机选择并删除数据
allkeys-lru 策略，使用 LRU 算法在所有数据中进行筛选
allkeys-lfu 策略，使用 LFU 算法在所有数据中进行筛选

LRU(Least Recently Used)算法，最近最不常用数据会被筛选出来。
MRU--LRU链表，访问到就放至MRU端，其余数据向后移一位。不过可想而知，简单使用LRU算法开销很大，首先得维护一个所有数据的链表，带来空间开销
且访问时需要移动链表。高频访问会带来大量开销，降低Redis性能。
所以Redis基于LRU算法做了简化，Redis默认会记录每个数据最近一次访问的时间戳，由RedisObject中的lru字段记录。然后在淘汰时，第一次会随机选出N个数据，
把它们作为一个候选集合，接下来Redis会比较集合数据中lru字段值，最小的淘汰。
Redis 提供了一个配置参数 maxmemory-samples，用于配置这个候选集合大小，CONFIG SET MAXMEMORY-SAMPLES 100
当需要再次淘汰时，Redis需要挑选数据进入第一次淘汰创建的候选集和，标准就是数据lru字段必须小于候选集合中最小的lru。
优先使用allkeys-lru策略，如果没有冷热数据区分，用allkeys-random。若有需要置顶数据需求，volatile-lru，置顶数据不设置过期时间，永不淘汰

一般缓存淘汰，干净数据直接删除、脏数据先写入数据库后再删除。但Redis在处理脏数据时也是直接删除，所以读写缓存只能是同步直写策略即修改缓存的同时修改数据库

3、如何解决缓存和数据库数据不一致问题？
读写缓存同步直写策略，需要使用事务机制，来保证缓存和数据库的更新具有原子性。
也可以使用重试机制，把第二步操作放入消息队列中，利用消息队列的重试机制。保证数据的一致性
以上是没有并发请求的情况。当有并发场景时
写读并发，有线程A先更新数据库，缓存还未更新，此时有并发线程B读数据，缓存命中，拿到的就是旧值。但线程A一般也会很快更新缓存，所以对业务影响较小。
写读并发，有线程A先更新缓存，数据库还未更新时，此时有并发线程B读数据，缓存命中，拿到的是更新后的新值，就算数据库还未更新，对业务也没影响
写写并发，先更新缓存再更新数据库，当有线程A和线程B同时更新一条数据，更新顺序是先A后B，但更新数据库是先B后A，这会导致数据库缓存不一致
写写并发，先更新数据库再更新缓存，当有线程A和线程B同时更新一条数据，数据库更新数据是先A后B，但缓存更新是先B后A，这也会导致数据库缓存不一致的情况。
写写并发的处理比较麻烦，对于写请求需要配合分布式锁使用。当写请求进来时，针对同一资源的修改操作，先加分布式锁，这样同一时间只允许一个线程去更新数据库和缓存，
没有拿到锁的线程把操作放入到队列中，延时处理。保证多个线程操作一个资源的顺序性，以此保证数据一致性。

只读缓存，在修改数据时需要把缓存中的数据删除，这样无论事先操作数据库还是先操作缓存，都有可能发生数据不一致的情况。
如何解决只读缓存数据不一致呢？
重试机制(利用消息队列)，把修改数据库或删除缓存放入消息队列中，当应用没能成功执行操作时，可以从消息队列重新读取消息，然后再次执行。
实际上，当两个操作第一次执行都没有失败，但有大量并发请求时，应用还是可能读到不一致的数据
情况一，先删缓存，再更新数据库。
线程A删除缓存，此时线程B来读数据发生缓存缺失，去数据库读，此时线程A还未更新数据库信息，线程B拿到旧值，因为发生缓存缺失所以线程B还会把旧值写入缓存，
这除了导致线程B拿到旧值外，之后线程读数据缓存击中拿到的还是旧值。为了解决问题，可以让第一次删除缓存线程在操作完数据库后sleep一段时间，再进行一次缓存删除。“延迟双删”
这里的sleep时间，需要大于线程B读取数据再写入缓存的时间，所以需要具体测试。
情况二，先更新数据库，再删缓存。
线程A更新了数据库，此时线程B来读数据，此时线程A还未删除缓存，缓存命中。线程B读取旧值，当并发请求量不大的时候，只会有少部分请求读到旧值，
且线程A一般也会很快删除缓存，之后的请求就会发生缓存缺失，读取数据库并写入缓存新值，所以这种情况一般对业务影响较小。
建议优先选择 先更新数据库再删缓存。原因有二，一是先删缓存会给数据库带来压力，二延迟双删的sleep时间不好控制

4、缓存雪崩、缓存击穿和缓存穿透问题
缓存雪崩，大量的应用请求无法在 Redis 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增
造成缓存雪崩的原因有二，一是大量数据设置了相同过期时间，导致某一时刻缓存大量失效，请求无法击中缓存。
可以通过设置过期时间相差几分钟，或者服务降级，即不是核心数据不予以处理直接返回预定义信息或者空置，核心数据任可以查询缓存，缺失时查询数据库
二，Redis实例宕机，无法处理请求，导致请求压至数据库，缓存雪崩。处理方式，服务熔断(暂定所有缓存or数据库访问)或者请求限流(只处理一定数量请求)
但这些处理都是在发生雪崩后的解决方式，我们更要做好的是提前预防，搭建Redis主从集群，添加哨兵，主库挂了可以进行主从切换等

缓存击穿，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，
导致了数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况，经常发生在热点数据过期失效时。
为了避免缓存击穿，热点数据不设置过期时间，让他一直保存在缓存中。

缓存穿透，要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。
如果持续有大量请求访问这些数据，就会同时给缓存和数据库带来压力。
一般导致缓存穿透的情况有两种
一是业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；二是恶意攻击：专门访问数据库中没有的数据
解决缓存穿透的办法
第一种方案是，缓存空值或缺省值
第二种方案是，使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力
布隆过滤器的实现，一个bit都为0的初始bit数组和N个哈希函数组成，对数据分别进行N个哈希函数运算后对数组长度取模得到在数组中的位置并置为1
在实际应用中，我们在写数据时，使用布隆过滤器进行bit位标记。当缓存缺失后，先对它进行布隆过滤即进行哈希运算后取模，若有一个位置上的bit值为0就表示不在数据库中。
布隆过滤器可以使用Redis实现，本身可以承担较大的并发访问量。
第三种方案是，在请求入口的前端进行请求检测，检测恶意请求

5、缓存污染，在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。
LFU策略，在LRU策略上做的优化。FU 策略中会从两个维度来筛选并淘汰数据：一是，数据访问的时效性（访问时间离当前时间的远近）；二是，数据的被访问次数
LFU策略淘汰数据时，会先根据数据的访问次数进行筛选，把访问次数最少的数据淘汰。若有相同访问次数的数据，再根据访问时效性，距离上次访问时间最久的淘汰。

Redis 在实现 LFU 策略的时候，只是把原来 24bit 大小的 lru 字段，又进一步拆分成了两部分
ldt 值：lru 字段的前 16bit，表示数据的访问时间戳；counter 值：lru 字段的后 8bit，表示数据的访问次数
但8个bit假如按线性增加的话，最多只能区分255次内的访问次数，显然是不够用的。Redis当然也考虑到了这一点，所以它对 counter值的增加并不是线性的，
而是设计了一个非线性增长的计数器来计算数访问次数，当lfu_log_factor参数设置为10就能很好用8bit区分十万级别的数据访问量了。100可以区分千万级访问量
需要注意的是，lfu-log-factor设置越大，递增概率越低。设置过大可能导致一些key的访问次数虽然高，但counter难以递增，进而导致访问频率更高的key优先被淘汰了。

若有短时热点访问数据，即短时间内访问次数很多但之后不会再访问了，Redis有counter自动衰减策略，即根据lfu_decay_time参数来控制访问次数的衰减。
以分钟为计时单位，当前时间和最近访问时间的分钟差/lfu_decay_time就是counter自动衰减数，假设参数设为1，N分钟内没有被访问，counter就要减N。
在有业务中有明确短时热点访问数据时，除了可以counter自动衰减外，还可以用volatile_lfu策略，根据访问时限给数据设置过期时间

6、Redis的并发更新，为了保证并发访问的正确性，Redis 提供了两种方法，分别是加锁和原子操作。
加锁是一种常见的方法，在读取数据前，客户端需要先获得锁，否则就无法进行操作。但加锁过多会影响到并发访问性能，
Redis客户端要加锁时，需要用到分布式锁，而分布式锁实现复杂，需要用额外的存储系统来提供加解锁操作

原子操作是另一种提供并发访问控制的方法。
我们所说的并发访问控制，实际就是指对多个客户端访问操作同一份数据的过程进行控制，以保证任何一个客户端发送的操作在 Redis 实例上执行时具有互斥性
客户端修改数据流程分为两步，读取修改，写回。Read-Modify-Write
为了实现并发控制要求的临界区代码互斥执行，Redis 的原子操作采用了两种方法:
把多个操作在 Redis 中实现成一个操作，也就是单命令操作；
把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本;
单命令操作：
Redis是使用单线程来串行执行处理客户端的请求操作命令的，所以Redis执行命令实际上就是互斥的了。
当我们对数据只是进行简单的增减逻辑，就可以用Redis提供的INCR/DECR 命令，把原先两步操作，变为一个原子性操作了。
Lua脚本：
但假如不是简单的增减数据，而是复杂的操作，单命令无法保证多个操作的互斥了，就只能使用Lua脚本了。
Lua脚本，Redis客户端可以通过EVAL命令调用Lua脚本。具体命令：redis-cli --eval lua.script keys,args
在编写 Lua 脚本时，你要避免把不需要做并发控制的操作写入脚本中
在使用通用Lua脚本时，建议先使用SCRIPT LOAD命令把 lua 脚本加载到 Redis 中，然后得到一个脚本唯一摘要值，
再通过EVALSHA命令 + 脚本摘要值来执行脚本，这样可以避免每次发送脚本内容到 Redis，减少网络开销

7、Redis实现分布式锁
Redis属于分布式系统，当有多个客户端需要争抢锁时，我们必须要保证，这把锁不能是某个客户端本地的锁。
所以我们需要实现分布式锁，此时，锁是保存在一个共享存储系统中的，可以被多个客户端共享访问和获取。
而Redis本身就是一个共享的存储系统，而且 Redis 的读写性能高，可以应对高并发的锁操作场景。

单机上的锁和分布式锁的区别。
单机上的锁，实际上加锁释放锁就是对一个变量进行操作，为0表示锁没被占用，为1表示被占用，释放锁就是将变量置为0。
分布式锁，同样可以使用一个变量来实现，加锁时同样需要判断锁变量的值，根据锁变量值来判断能否加锁成功；
只是在分布式的场景下，锁变量需要由一个共享存储系统来维护，只有这样多个客户端才可以通过访问共享存储系统来访问锁变量。
相应的，加锁和释放锁的操作就变成了"读取、判断、设置"共享存储系统中的锁变量值。
这样一来，我们就可以得出实现分布式锁的两个要求
要求一：分布式锁的加锁和释放锁的过程，涉及多个操作。所以，在实现分布式锁时，我们需要保证这些锁操作的原子性；
要求二：共享存储系统保存了锁变量，如果共享存储系统发生故障或宕机，那么客户端也就无法进行锁操作了。所以要共享存储系统高可靠性

基于单个Redis节点实现分布式锁
SETNX和DEL命令结合使用，SETNX表示键不存在时则创建键值对并赋值，如果存在，就不做任何设置。SETNX key value
对于释放锁，我们可以在执行完业务逻辑后，用DEL命令删除锁变量即键值对。DO SOMETHING 后 DEL key
但这么实现有两个风险：
一是假设SETNX后，在业务操作中发生异常，一直没有执行最后的DEL命令，导致锁一直无法释放。解决办法，给锁变量设置一个过期时间。
二是假设客户端A执行SETNX加锁后，客户端B执行了DEL命令释放锁，此时客户端A的锁就被误释放了，如果客户端C正好也申请加锁，就会成功获取锁，
进而导致并发操作共享数据，数据就会被错误修改，这是无法接受的。

如何来区分来自不同客户端的锁操作请求呢？
使用SET操作带上NX和EX/PX选项。Redis也为SET操作提供了类似SETNX命令效果的NX选项，用来实现“不存在即设置”。
此外，SET 命令在执行时还可以带上 EX 或 PX 选项，用来设置键值对的过期时间。SET key value [EX seconds | PX milliseconds] [NX]
例：SET lock_key unique_value NX PX 10000，unique_value就是客户端唯一标识。
释放锁的过程，因为也涉及到读取、判断、删除变量的多个操作，所以也需要保证操作的原子性，可以使用Lua脚本来实现。
redis-cli --eval unlock.script lock_ley, unique_value
这就是SET命令和Lua脚本结合使用的单节点分布式锁实现。

基于多个Redis节点实现高可靠的分布式锁
RedLock算法，基本思路是让客户端和多个独立的Redis实例依次请求加锁，如果半数以上的Redis实例成功完成加锁操作，那我们就认为客户端成功获取了分布式锁。
三步加锁的执行步骤，N个Redis实例：
第一步是，客户端获取当前时间
第二步是，客户端按顺序依次向 N 个 Redis 实例执行加锁操作。使用SET命令带上NX和EX/PX选项。
需要设置一个加锁超时时间，保证单个Redis实例加锁失败，后续Redis实例能继续正常加锁。超时时间要远小于锁的过期时间
第三步是，一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时。满足下列两个条件才能认为加锁成功
条件一：客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁；
条件二：客户端获取锁的总耗时没有超过锁的有效时间
若没能满足，客户端向所有Redis节点发起释放锁的操作。释放锁和单个Redis节点一样，利用Lua脚本执行。

8、Redis如何实现事务？

Redis性能影响篇
1、Redis内部的阻塞式操作,首先了解Redis的阻塞点有哪些？



























































