消息队列
1、消息队列的选择必须开源，产生业务bug了可以能够修改源代码。RabbitMQ Erlang语言不易进行二次开发

2、RocketMQ响应延迟低，主要可用于处理在线业务以及金融业务。低延迟稳定性高，设计思想尽快的及时处理(java开发)

3、kafka高流量，设计思想异步和批处理。攒一波再处理，所以延迟比RocketMQ高。(scala java开发)

4、RocketMQ是典型的发布-订阅模式(publish-subscribe)，即生产者、主题(topic)、多个订阅者。只要订阅者订阅了这个主题就可以消费完主题里所有消息
但大多数消息队列产品都是“请求-确认”机制来保证数据的可靠性不丢失，即发送和消费成功后都会向上一级发送确认的响应。
但为了确保消息的有序性，在某一条消息成功消费前，下一条消息是不能被消费的，否则可能出现上一条消息空洞，违背了有序性。
但这个机制导致无法水平扩展消费者，达到提高消费端的总体性能，RocketMQ为此在主题下面增加了队列的概念。

每个主题又包含了多个队列，通过多个队列来实现多实例并行生产和消费。需要注意的是，RocketMQ 只在队列上保证消息的有序性，主题层面是无法保证消息的严格顺序的
RocketMQ中的订阅者是通过消费组(Consumer Group)来实现的，每个消费组都消费主题中一份完整的消息，不同消费组之间消费进度彼此不受影响，
也就是说，一条消息被 Consumer Group1 消费过，也会再给 Consumer Group2 消费。但同组的消费者已经消费了，同组其他消费者就不会再消费了。

由于消息需要被不同的消费组多次消费，所以消费完的消息不会立即清除，这就需要RocketMQ为每个消费组在每个队列上维护一个消费位置(Consumer Offset)
这个位置之前的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一
需要注意的是，消费位置和消费者是没有关系的。当消费组在这个队列上的消费位置是5，表示5之前的消息都被消费完了，之后的没有被消费或正在被消费
一般来说每个队列只会分配一个消费者，因为队列里消息的消费实际上就是一个单线程的

那么如果我的业务不需要保证顺序执行，我想在单个队列上并行消费呢，可以多个消费者并行消费，但可能会出现消息空洞。即我6、7消费完响应回来了但5一直不返回ack，
这时我的消费位置应该在哪呢？为了避免整个队列卡住，可以先把消息5这条消息复制到一个特殊重试队列中，然后以然把消费位置更新为8，继续后面的消费。
再有消费者来pull消息的时候，优先把重试队列的消息给消费者就行了。
需要注意的是，并行消费单个队列开销很大，不应该作为常规提升消息并发的手段，消费慢还是应该多增加消费者实例

5、kafka的消息模型和RocketMQ一模一样，只是在队列的概念上，kafka名称是用的分区(partition),含义和功能上没有任何区别

6、利用消息队列实现分布式事务，RocketMQ消息事务。订单系统在消息队列上开启一个事务。
然后订单系统给消息服务器发送一个“半消息”，这个半消息不是说消息内容不完整，它包含的内容就是完整的消息内容，
半消息和普通消息的唯一区别是，在事务提交之前，对于消费者来说，这个消息是不可见的。
半消息发送成功，订单系统执行本地事务(创建订单)，在订单库中创建一条订单记录，并提交订单库的数据库事务。
当订单成功创建后，提交事务消息(此步骤可能失败，又会导致信息不一致的情况)，购物车系统可以消费这条消息删除之前的购物车中物品
若失败，则回滚事务消息，购物车系统就不会收到这条消息。这样就达到成功就都成功，失败都失败效果。

上述说的提交事务消息若失败，Kafka直接会抛出异常，开发人员捕捉自行处理。RocketMQ则有事务反查机制

7、确保消息可靠传递，生产阶段、存储阶段、消费阶段
生产阶段: 在这个阶段，从消息在 Producer 创建出来，经过网络传输发送到 Broker 端
存储阶段: 在这个阶段，消息在 Broker 端存储，如果是集群，消息会在这个阶段被复制到其他的副本上
消费阶段: 在这个阶段，Consumer 从 Broker 上拉取消息，经过网络传输发送到 Consumer 上

生产阶段，producer收到了broker的确认响应，就可以保证在生产阶段消息没有丢失。所以编写发送消息代码时，需要注意，正确处理返回值或者捕获异常
同步发送时，只要注意捕获异常即可。异步发送时，则需要在回调方法里进行检查
存储阶段，可以通过配置 Broker 参数来避免因为宕机丢消息。对于单个节点的broker，在写入磁盘后再给生产者发送确认响应
例如，在 RocketMQ 中，需要将刷盘方式 flushDiskType 配置为 SYNC_FLUSH 同步刷盘
如果broker是由多个节点组成的集群，则需要将broker配置成至少将消息发送到2个以上的节点再给客户端发送确认响应。
消费阶段，不要在收到消息后就立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确认
如果 Broker 没有收到消费确认响应，下次拉消息的时候还会返回同一条消息

8、消息重复怎么办？
消息传递的三种服务质量标准，At Most Once、At Least Once、Exactly Once
幂等性，一个幂等操作的特点是，其任意多次执行所产生的影响均与一次执行的影响相同
At least once + 幂等消费 = Exactly once

常用设计幂等操作的方法:
利用数据库的唯一约束实现幂等
例如一个账户的余额增加100元，显然这个消息本身是不幂等的。
但我们可以把消费消息的逻辑变为，向一张转账流水表里新增一条记录，然后再根据转账记录表里的数据异步更新用户余额即可。
转账流水表里有转账单id、账户id的唯一约束，这样就只能插入一条数据实现消息幂等性。
基于这个思路，不光是关系型数据库能增加唯一约束来实现。只要类似有insert if not exist语义的存储系统都可以用于实现幂等。
比如redis的setnx命令来代替数据库里的唯一约束

为更新的数据设置前置条件
这种实现幂等的思路是给数据变更设置一个前置条件。只有当满足前置条件时，才更新数据。
还是这个例子，给账户余额增加100元。可以在producer发消息时，将当前账户余额写入消息体中。只有在账户余额为这个数值时才增加100。
对于复杂的业务场景，就可以给数据增加一个版本号写入消息体中，更新时比较版本号是否和消息体中记录的一致，一致则更新。更新完给版本号+1

记录并检查操作
通用性最强的方法，也称为“Token 机制或者 GUID（全局唯一 ID）机制。实现的思路特别简单：在执行数据更新操作之前，先检查一下是否执行过这个更新操作
具体实现是，给消息增加一个唯一的GUID，消费时，先根据这个 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费
但在分布式系统中，这个方式是最难实现的，这个需要满足“检查消费状态，然后更新数据并且设置消费状态”中，三个操作必须作为一组操作，保证原子性。
例如有一条GUID为666的消息，给账户1增加100元， 当consumer1拿到这条消息时，检查状态还未被消费，执行增加100元，此时consumer2也拿到了这条消息，
但consumer1还未将这条消息状态更新为已消费，consumer2判断完状态也会直接执行增加100元操作。
当然我们可以用分布式事务或者分布式锁来实现，但都是比较难解决的问题

9、预防消息积压问题
在消息的收发两端，我们的业务代码怎么和消息队列配合，达到一个最佳的性能(消息队列服务通常不需要我们考虑，他的性能已经比绝大部分业务服务处理能力高很多了)
发送端性能优化
如果说，你的代码发送消息的性能上不去，你需要优先检查一下，是不是发消息之前的业务逻辑耗时太多导致的
设置合适的并发和批量大小，就可以达到很好的发送性能
例如微服务，主要接受RPC请求处理在线业务，就直接在当前处理请求的线程发送消息就可以了，因为RPC框架都是多线程支持并发的。
并且在线业务都比较在意的是请求响应时延，批量发必定会影响时延。这种就是通过并发来提升发送效率
离线分析系统，这种关心的不是时延问题而是更关心系统的吞吐量，这种就适合批量发送，同样也可以使用少量的并发就达到非常高的吞吐量

消费端性能优化
一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康的持续运行
除了优化消费端的业务逻辑以外，也可以通过水平扩容，增加消费端的实例并发数来提升总体消费性能，但要特别注意的一点是，
在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的。
如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的。原因我们之前讲过，因为对于消费者来说，在每个分区上实际上只能支持单线程消费

有一种消费端性能优化的方式，就是在收到消息的OnMessage方法中，不处理任何业务逻辑，把这个消息放入内存队列里就返回了。然后再启动很多的业务线程，
这些业务线程才是真正处理消息的业务逻辑。业务线程从内存队列里取消息处理，解决了单个consumer不能并行消费的问题。但这种方法其实是错误的！！！
因为当这个consumer实例宕机了，内存队列里的消息就会丢失！！

10、如果消息积压了该如何处理？
最粗粒度的原因，只有两种：要么是发送变快了，要么是消费变慢了
大部分消息队列都内置了监控功能，通过监控很容易就能确定是哪种原因。
发送增多
消费变慢，你需要检查你的消费实例，分析一下是什么原因导致消费变慢。优先检查一下日志是否有大量的消费错误，如果没有错误的话，
可以通过打印堆栈信息，看一下你的消费线程是不是卡在什么地方不动了，比如触发了死锁或者卡在等待某些资源上了

11、Netty异步网络IO框架，只用少量的线程就能处理大量的连接，有数据到来的时候能第一时间处理就可以了(相关知识点：常见笔记36,NIO实现异步网络通信)

首先我们创建了一个 EventLoopGroup 对象，命名为 group，这个 group 对象你可以简单把它理解为一组线程。这组线程的作用就是来执行收发数据的业务逻辑
然后，使用 Netty 提供的 ServerBootstrap 来初始化一个 Socket Server，绑定到本地 9999 端口上
在真正启动服务之前，我们给 serverBootstrap 传入了一个 MyHandler 对象，这个 MyHandler 是我们自己来实现的一个类，它需要继承 Netty 提供的一个抽象类：ChannelInboundHandlerAdapter，在这个 MyHandler 里面，我们可以定义收到数据后的处理逻辑。这个设置 Handler 的过程，就是我刚刚讲的，预先来定义回调方法的过程
最后就可以真正绑定本地端口，启动 Socket 服务了

12、消息队列的网络传输就面临这必须要序列化反序列化结构化数据，怎样做才能实现高性能的序列化与反序列化呢
常见的序列化方式，JSON、XML标准数据格式 这种可读性高，但数据密度低，占用的字节量大
Kryo、Hessian等通用的二进制序列化实现，适用范围广，可读性低，但性能会比JSON这些要好，但还是不如专用的序列化实现

那怎么才能实现高性能的序列化与反序列化呢？专用的序列化实现，可以提高序列化性能，并有效减小序列化后的字节长度
例如，User对象有三个属性name,age,married，通常json格式{"user" : "cwr", "age" : "25", "married" : true} 需要占用大量字节
假如定义一个专用的序列化实现，将这个对象序列化成 02|03 63 77 72|19|01
首先02是我们自定义User类型对应的字节编号,我们再按照自定的顺序存放他的属性(name|age|married)。这种序列化方法显然更高效，序列化出来的字节也更少
但，专用的序列化实现缺点明显，需要为每种对象类型定义专门的序列化与反序列化方式，实现复杂。

13、传输协议，应用程序之间对话的语言
断句，断句不对语义也会有很大改变，常见的断句方式HTTP1协议里的分隔符，但这种就需要考虑到本身数据中有可能带上定义的分隔符，就涉及到传输前的转义和收到数据后的转义
还有一种就是，给每句话前加上一个数字，代表这段话的长度。例如03 下雨天 03留客天 02天留 03我不留。这种比分隔符看上去更简单性能也好很多，这是最常用的分割数据的方法

用双工收发协议提升吞吐量，HTTP1是单工通道，TCP协议是全双工通道。
单工协议，客户端和服务端建立连接之后，发送请求后直到当服务端返回响应或请求超时，这段时间内这个通道是不能再发送任何请求的，效率低。解决方法只有建立多个通道
双工协议，你可以同时进行数据的双向收发，互相是不会受到任何影响的。要提高吞吐量，应用层的协议也必须支持双工通信
但双工协议就会出现一个问题，在多线程并发的环境下，请求和响应是没有顺序的。
在实际上设计协议的时候，我们一般不关心顺序，只要需要确保请求和响应能够正确对应上就可以了，可以这样解决，
发送请求的时候给每个请求加一个序号，序号在本次会话中保持唯一性。然后在响应中带上请求的序号，这样就可以把请求和响应对应上了

14、内存管理：如何避免内存溢出和频繁的垃圾回收
Java中内存是自动管理的，我们在编写代码的时候，不需要显式去申请和释放内存
申请内存很简单，计算要创建对象所需占用的内存大小，在内存中找一块连续并且空闲的内存空间，标记为已占用。申请的内存地址绑定到对象的引用上，这时候对象就可以使用了
内存回收就非常复杂了，现代的 GC 算法大多采用的是“标记 - 清除”算法或是他的变种算法。
标记阶段：从 GC Root 开始，你可以简单地把 GC Root 理解为程序入口的那个对象，标记所有可达的对象，因为程序中所有在用的对象一定都会被这个 GC Root 对象直接或者间接引用
清除阶段：遍历所有对象，找出所有没有标记的对象。这些没有标记的对象都是可以被回收的，清除这些对象，释放对应的内存即可
这个算法有个最大的问题就是，在执行标记和清除过程中，必须把进程暂停，否则计算结果就是不准确的。
完成对象回收后，还需要整理内存碎片，将不连续的空闲内存移动到一起，以便空出足够的连续内存空间供后续使用

15、缓存策略，缓存可以有效减少磁盘IO提高应用性能，但是选择读写缓存还是只读缓存呢？

16、只有在并发环境中，共享资源不支持并发访问，或者说并发访问共享资源会导致系统错误的情况下，才需要使用锁
导致死锁的三种情况：获取锁但没有释放锁、在一个线程中获取了锁后再次获取同一把锁，但这个锁并不是重入锁
多个锁在不同线程中相互占用，占用后互相等待
例如，线程A LOCKA(占用) LOCKB 、线程B LOCKB(占用) LOCKC、线程C LOCKC(占用) LOCKA
避免第三种死锁情况发生的方式：
尽量避免在持有一把锁的情况下，去获取另外一把锁，就是要尽量避免同时持有多把锁；
如果需要持有多把锁，一定要注意加解锁的顺序，解锁的顺序要和加锁顺序相反。比如，获取三把锁的顺序是 A、B、C，释放锁的顺序必须是 C、B、A；
给你程序中所有的锁排一个顺序，在所有需要加锁的地方，按照同样的顺序加解锁；
例如例子中我把线程C加锁顺序改为LOCKA LOCKC，就不会发生死锁情况了

使用读写锁要兼顾性能和安全性。大部分情况下，数据的读写比是不均衡的，读要远远多于写，所以我们希望，
读访问可以并发执行，写的同时不能并发读，也不能并发写。这样就兼顾了性能和安全性
例如我们并发包里的，ReentrantReadWriteLock类

Python中提供了try-with-lock不需要显示地获取和释放锁，非常方便。很遗憾Java中没有这个机制，如何在Java中自己实现一个try-with-lock呢？
利用try-with-resource，try(块中资源使用完会自动释放的特性，implements Closeable接口，重写close方法中释放锁){}即可实现

17、CAS计算机原语操作，CompareAndSwap,伪代码cas(*p, old, new) p是需要替换数据的地址，old为旧值，new为新值。
当*p中数据的值等于old时，进行swap并返回true，否则返回false。计算机原语操作，他由CPU提供给了原子性，
在并发环境中，单独使用这些原语不用担心数据安全问题。在特定的场景中，CAS 原语可以替代锁，在保证安全性的同时，提供比锁更好的性能

18、Kafka、RocketMQ数据压缩策略(压缩实际上是CPU资源换空间(空间减小会间接提升网络传输效率)，压缩非常消耗CPU计算资源)
Kafka 是否开启压缩，这是可以配置，它也支持配置使用哪一种压缩算法。
不同的业务场景是否需要开启压缩，选择哪种压缩算法是不能一概而论的。所以，Kafka 的设计者把这个选择权交给使用者
开启压缩后，kafka选择一批消息一起压缩，每批消息就是一个压缩分段。可以通过参数来控制每批消息的大小
在Kafka中，生产者生成一个批消息发给服务端，在服务端中是不会拆分批消息的。那按照批来压缩，意味着，在服务端也不用对这批消息进行解压，
可以整批直接存储(不会浪费CPU资源，同时占用储存空间减少，占用传输带宽笑)，然后整批发送给消费者。最后，批消息由消费者进行解压。
在Broker中只会对header进行解压，消息体不会

RocketMQ，在DefaultMQProducerImpl.java(m tryToCompressMessage)源码中可以看到，RocketMQ只支持ZIP压缩算法，且不支持Batch消息压缩

20、RocketMQ Producer源码分析，使用到的设计模式，外观模式(MQProducer、DefaultMQProducer)、单例模式、状态模式(DefaultMQProducerImpl.start)、
策略模式(选择哪个队列发送由 MessageQueueSelector#select 方法决定)
几个重要的业务逻辑实现类，DefaultMQProducerImpl 封装了大部分 Producer 的业务逻辑，MQClientInstance 封装了客户端一些通用的业务逻辑，
MQClientAPIImpl 封装了客户端与服务端的 RPC，NettyRemotingClient 实现了底层网络通信

http协议发一个请求到服务端，就是发了一些数据过来，服务端回响应也就是在这个连接上给它返回一些数据回去就可以了。
至于什么时候往回发响应数据，哪个线程来发，有要求吗？并没有。只要在超时之前发响应就可以了。我们讲得如何来实现异步网络IO的方法处理的不就是这种情况吗？

21、Kafka Consumer消费流程。

























